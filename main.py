import os
import time
import mlflow

from data_loader import load_data 
from data_preprocessing import preprocess_data
from model_training import train_models
from model_evaluation import evaluate_models

if __name__ == "__main__":
    start_time = time.time()

    # ‚úÖ Set remote MLflow tracking URI for DagsHub
    mlflow.set_tracking_uri("https://dagshub.com/jeevitharamsudha16/Extrovert-vs.-Introvert-Classification-End-to-End-MLOps-Pipeline-with-DVC-MLflow-CI-CD.mlflow")

    # ‚úÖ Use your experiment name (must match or pre-create in DagsHub UI)
    mlflow.set_experiment("Personality_Classification")

# ‚úÖ Read credentials from environment variables set by GitHub Actions
    os.environ["MLFLOW_TRACKING_USERNAME"] = os.getenv("MLFLOW_TRACKING_USERNAME")
    os.environ["MLFLOW_TRACKING_PASSWORD"] = os.getenv("MLFLOW_TRACKING_PASSWORD")

    # ‚úÖ Authenticate using your DagsHub token as MLflow username
    #os.environ["MLFLOW_TRACKING_USERNAME"] = os.getenv("DAGSHUB_TOKEN")
    #os.environ["MLFLOW_TRACKING_PASSWORD"] = ""

    # Debug: confirm tracking URI
    print(f"üì° MLflow Tracking URI (from script): {mlflow.get_tracking_uri()}")

    try:
        # üöÄ Step 1: Load Raw Data
        df = load_data("data/personality_dataset.csv")
        print("\nüìä First 5 rows of raw dataset:")
        print(df.head())

        # üßπ Step 2: Preprocess Data
        X_train, X_test, y_train, y_test, label_encoders = preprocess_data(df)

        # ü§ñ Step 3: Train Models
        train_models(X_train, y_train)

        # üß™ Step 4: Evaluate Models and log to remote MLflow
        evaluate_models(X_test, y_test, model_dir="artifacts/models", log_to_mlflow=True)

        print("\n‚úÖ Pipeline completed successfully!")

    except Exception as e:
        print(f"\n‚ùå Pipeline failed due to: {e}")

    end_time = time.time()
    print(f"\n‚è±Ô∏è Total time taken: {end_time - start_time:.2f} seconds")
